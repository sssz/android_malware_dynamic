import tensorflow as tf
K = tf.keras.backend
from data_loader import (vectorization_main, vectorization_andmal2017, vectorization_mix, vectorization_hybrid)

from keras.models import Sequential
from keras.layers import Dense
# from keras.wrappers.scikit_learn import KerasClassifier
# from sklearn.model_selection import cross_val_score
# from sklearn.preprocessing import LabelEncoder
# from sklearn.model_selection import StratifiedKFold

from metrics import precision, recall, f1_score as f1
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from tensorflow.examples.tutorials.mnist import input_data
from keras.callbacks import TensorBoard

def DNN(input_dim, output_dim):
    model = Sequential()
    model.add(Dense(units=30, input_shape=(input_dim,), activation='relu'))
    model.add(Dense(units=25, input_shape=(30,), activation='relu'))
    model.add(Dense(units=output_dim, input_shape=(25,), activation='sigmoid'))
    
    # Compile model
    #model.compile(loss='binary_crossentropy', optimizer=tf.train.AdamOptimizer(1), metrics=['binary_accuracy'])
    model.compile(optimizer = tf.train.AdamOptimizer(0.00002),loss = 'binary_crossentropy',metrics= ['binary_accuracy', precision, recall, f1])
    model.summary()
    return model
    # evaluate model with standardized dataset
    #estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)
    #kfold = StratifiedKFold(n_splits=10, shuffle=True)
    #results = cross_val_score(estimator, X, encoded_Y, cv=kfold)
    #print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))


def train():
    dnn = DNN(808, 1)
    #X_train, X_test, y_train, y_test = vectorization_main()
    #X_train, X_test, y_train, y_test = vectorization_main(data_name = "drebin", feature_name = "dynamic.json")
    X_train, X_test, y_train, y_test = vectorization_hybrid(data_name = "drebin")
    #X_train, X_test, y_train, y_test = vectorization_andmal2017()
    #X_train, X_test, y_train, y_test = vectorization_mix()
    print(X_train.shape, y_train.shape)
    import time
    s_time = time.time()
    dnn.fit(X_train, y_train, 
        epochs=300, 
        batch_size=32, 
        validation_data=(X_test, y_test), 
        callbacks=[TensorBoard(log_dir='./tmp/log')])
    print("time cost:", time.time() - s_time)
    y_pred = dnn.predict(X_test)
    y_pred = np.array([1 if y[0] > 0.5 else 0 for y in y_pred])

    return accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)

def evaluate():
    result = []
    try_cnt = 30
    for i in range(try_cnt):
        result.append(train())
    acc = sum([result[i][0] for i in range(try_cnt)])/try_cnt
    pre = sum([result[i][1] for i in range(try_cnt)])/try_cnt
    rec = sum([result[i][2] for i in range(try_cnt)])/try_cnt
    f1 = sum([result[i][3] for i in range(try_cnt)])/try_cnt
    print(acc, pre, rec, f1)
    #0.9640422631220174 0.9388329089180775 0.9416478345079741 0.9400349661664494
    #0.964212678936605 0.933632112162519 0.9458280650798727 0.9395342348449509
    '''
    static:
    0.9614178595773685 0.9279059066372713 0.9446482296821228 0.9360722788879502
.9795588235294116 0.9765911694396493 0.9812007298845338 0.9788811997759309    
    dynamic:
    0.9153333333333334 0.8480728575558061 0.8788520178103739 0.8626707964384229
    hybrid:
    0.965405589638718 0.9347759799222447 0.9513713854757139 0.942918983608054
0.9855882352941177 0.9881960384506797 0.981910777176101 0.9850364980891353
    '''
if __name__ == '__main__':
    print(train())
    #evaluate()