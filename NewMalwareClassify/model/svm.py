from sklearn import svm
from data_loader import (vectorization_main, vectorization_andmal2017, vectorization_mix)
#from metrics import precision, recall, f1_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


def train():
    #X_train, X_test, y_train, y_test = vectorization_main()
    #X_train, X_test, y_train, y_test = vectorization_andmal2017()
    X_train, X_test, y_train, y_test = vectorization_mix()
    classifier=svm.SVC(gamma='auto', decision_function_shape='ovo')
    classifier.fit(X_train, y_train)
    #score = classifier.score(X_test, y_test)
    y_pred = classifier.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(acc, precision, recall, f1)
    return acc, precision, recall, f1

def evaluate():
    result = []
    try_cnt = 30
    for i in range(try_cnt):
        result.append(train())
    acc = sum([result[i][0] for i in range(try_cnt)])/try_cnt
    pre = sum([result[i][1] for i in range(try_cnt)])/try_cnt
    rec = sum([result[i][2] for i in range(try_cnt)])/try_cnt
    f1 = sum([result[i][3] for i in range(try_cnt)])/try_cnt
    print(acc, pre, rec, f1) 
    '''
    derbn0 vs benign
        0.9386843899113841 0.8918344238355598 0.909683549032539 0.9002710534363695
    andmal2017 vs benign
        0.8908975979772441 1.0 0.20902194050893483 0.3446623585572391
    '''
if __name__ == "__main__":
    #train()
    evaluate()