import tensorflow as tf
from sklearn.model_selection import train_test_split
K = tf.keras.backend

from data_loader import vectorization_main
from metrics import precision, recall, f1_score as f1
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

class MyLayer(tf.keras.layers.Layer):
    def __init__(self, input_dim, output_dim=50, **kwargs):
        self.input_dim = input_dim
        self.output_dim = output_dim
        super(MyLayer, self).__init__(**kwargs)
    def build(self, input_shape):
        self.kernel = self.add_weight(name='kernel', 
                                      shape=(self.input_dim, self.output_dim),
                                      initializer='glorot_uniform',
                                      trainable=True)
        super(MyLayer, self).build(input_shape)

    def call(self, x):
        a = K.pow(K.dot(x,self.kernel), 2)
        b = K.dot(K.pow(x, 2), K.pow(self.kernel, 2))
        return 0.5 * K.sum(a-b, 1, keepdims=True)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], self.output_dim)

def FM(feature_dim):
    inputs = tf.keras.Input((feature_dim,))
    liner = tf.keras.layers.Dense(units=1, 
                                  bias_regularizer=tf.keras.regularizers.l2(0.01),
                                  kernel_regularizer=tf.keras.regularizers.l1(0.02),
                                  )(inputs)
    cross = MyLayer(feature_dim)(inputs)
    add = tf.keras.layers.Add()([liner, cross])
    predictions = tf.keras.layers.Activation('sigmoid')(add)
    model = tf.keras.Model(inputs=inputs, outputs=predictions)
    model.compile(loss='binary_crossentropy',
                  optimizer=tf.train.AdamOptimizer(0.001),
                  metrics=['binary_accuracy', precision, recall, f1])
    model.summary()
    return model

def train():
    fm = FM(808)
    X_train, X_test, y_train, y_test = vectorization_main()
    print(X_train.shape)
    fm.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))
    y_pred = fm.predict(X_test)
    y_pred = np.array([1 if y[0] > 0.5 else 0 for y in y_pred])

    return accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)

def evaluate():
    result = []
    try_cnt = 30
    for i in range(try_cnt):
        result.append(train())
    acc = sum([result[i][0] for i in range(try_cnt)])/try_cnt
    pre = sum([result[i][1] for i in range(try_cnt)])/try_cnt
    rec = sum([result[i][2] for i in range(try_cnt)])/try_cnt
    f1 = sum([result[i][3] for i in range(try_cnt)])/try_cnt
    print(acc, pre, rec, f1)
    
    #FM: 0.9704839809134284 0.9627679141270874 0.9378616552582428 0.9499759209984381
    #DNN:0.9640422631220174 0.9388329089180775 0.9416478345079741 0.9400349661664494
    #RF: 0.9604635310156779 0.966719876336477 0.8997544401225606 0.9318782426822927
    #SVM:0.9386843899113841 0.8918344238355598 0.909683549032539 0.9002710534363695
if __name__ == '__main__':
    #train()
    evaluate()